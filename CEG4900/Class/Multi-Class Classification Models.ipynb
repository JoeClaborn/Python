{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ae721ee",
   "metadata": {},
   "source": [
    "# Train a multi-class classification model using PyTorch\n",
    "\n",
    "We use the iris dataset to train and test this multi-class classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab875870-f105-41c5-9fc2-38370c357b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put all the libraries here\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397c824-9fb2-4a3e-b451-92a867420cab",
   "metadata": {},
   "source": [
    "## Load iris dataset from scikit-learn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be13a314-a51c-4941-8651-1a8b4a337ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********Classe names***********\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "***********Feature names***********\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "***********Data sample festure values***********\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "***********Data size and feature size***********\n",
      "(150, 4)\n",
      "***********Data label values***********\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "\n",
    "#Classe names\n",
    "print(\"***********Classe names***********\")\n",
    "print(iris.target_names)\n",
    "#Feature names\n",
    "print(\"***********Feature names***********\")\n",
    "print(iris.feature_names)\n",
    "#Data sample festure values\n",
    "print(\"***********Data sample festure values***********\")\n",
    "print(iris.data)\n",
    "print(\"***********Data size and feature size***********\")\n",
    "print(iris.data.shape)\n",
    "#Data label values\n",
    "print(\"***********Data label values***********\")\n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c12167c",
   "metadata": {},
   "source": [
    "## Convert the data to PyTorch tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "601fef4b-badd-4fe6-a456-2ccafffaaafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = iris.data, iris.target\n",
    "\n",
    "#Split the data into two sets: 80% for training and 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create a TensorDataset for training and testing, respectively\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders: here, we use mini-batch gradient descent, so need to specify the batch size\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33e78bc",
   "metadata": {},
   "source": [
    "## Construct a multi-class classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31221457",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassification, self).__init__()\n",
    "        #The first \"4\" specifies that the feature dimension is 4, and the second \"3\" specifies that this is 3-class classification\n",
    "        self.fc = nn.Linear(4, 3) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdff37a",
   "metadata": {},
   "source": [
    "## Set up some hyperparameters: use cross entropy loss, gradient descent with Adam optimizer, learning rate, and epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f24ac63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiClassification(\n",
      "  (fc): Linear(in_features=4, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "learning_rate = 0.01\n",
    "lossfunction = nn.CrossEntropyLoss() #Cross entropy loss for multi-class classification\n",
    "\n",
    "#Instantiate the model from \"MultiClassification\" class definition\n",
    "model = MultiClassification()\n",
    "\n",
    "#Use Adam optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fee198",
   "metadata": {},
   "source": [
    "## Train the model using training data (X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbfe9108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch (1): Train accuracy: 0.3417, loss: 0.212\n",
      "epoch (2): Train accuracy: 0.3417, loss: 0.124\n",
      "epoch (3): Train accuracy: 0.3583, loss: 0.073\n",
      "epoch (4): Train accuracy: 0.5750, loss: 0.068\n",
      "epoch (5): Train accuracy: 0.6583, loss: 0.063\n",
      "epoch (6): Train accuracy: 0.6667, loss: 0.056\n",
      "epoch (7): Train accuracy: 0.7833, loss: 0.052\n",
      "epoch (8): Train accuracy: 0.7917, loss: 0.049\n",
      "epoch (9): Train accuracy: 0.7167, loss: 0.047\n",
      "epoch (10): Train accuracy: 0.6833, loss: 0.044\n",
      "epoch (11): Train accuracy: 0.7750, loss: 0.042\n",
      "epoch (12): Train accuracy: 0.8250, loss: 0.042\n",
      "epoch (13): Train accuracy: 0.7667, loss: 0.040\n",
      "epoch (14): Train accuracy: 0.7167, loss: 0.038\n",
      "epoch (15): Train accuracy: 0.7167, loss: 0.037\n",
      "epoch (16): Train accuracy: 0.8750, loss: 0.037\n",
      "epoch (17): Train accuracy: 0.9000, loss: 0.036\n",
      "epoch (18): Train accuracy: 0.7333, loss: 0.035\n",
      "epoch (19): Train accuracy: 0.8667, loss: 0.034\n",
      "epoch (20): Train accuracy: 0.9167, loss: 0.034\n",
      "epoch (21): Train accuracy: 0.9417, loss: 0.033\n",
      "epoch (22): Train accuracy: 0.9667, loss: 0.032\n",
      "epoch (23): Train accuracy: 0.8500, loss: 0.032\n",
      "epoch (24): Train accuracy: 0.9000, loss: 0.031\n",
      "epoch (25): Train accuracy: 0.9583, loss: 0.030\n",
      "epoch (26): Train accuracy: 0.9750, loss: 0.030\n",
      "epoch (27): Train accuracy: 0.9417, loss: 0.030\n",
      "epoch (28): Train accuracy: 0.9167, loss: 0.029\n",
      "epoch (29): Train accuracy: 0.9583, loss: 0.029\n",
      "epoch (30): Train accuracy: 0.9500, loss: 0.029\n",
      "epoch (31): Train accuracy: 0.9583, loss: 0.028\n",
      "epoch (32): Train accuracy: 0.9500, loss: 0.028\n",
      "epoch (33): Train accuracy: 0.8917, loss: 0.028\n",
      "epoch (34): Train accuracy: 0.9583, loss: 0.028\n",
      "epoch (35): Train accuracy: 0.9833, loss: 0.027\n",
      "epoch (36): Train accuracy: 0.9750, loss: 0.026\n",
      "epoch (37): Train accuracy: 0.9333, loss: 0.026\n",
      "epoch (38): Train accuracy: 0.9250, loss: 0.027\n",
      "epoch (39): Train accuracy: 0.9583, loss: 0.026\n",
      "epoch (40): Train accuracy: 0.9750, loss: 0.025\n",
      "epoch (41): Train accuracy: 0.9250, loss: 0.025\n",
      "epoch (42): Train accuracy: 0.9667, loss: 0.025\n",
      "epoch (43): Train accuracy: 0.9750, loss: 0.024\n",
      "epoch (44): Train accuracy: 0.9667, loss: 0.025\n",
      "epoch (45): Train accuracy: 0.9667, loss: 0.024\n",
      "epoch (46): Train accuracy: 0.9750, loss: 0.024\n",
      "epoch (47): Train accuracy: 0.9583, loss: 0.024\n",
      "epoch (48): Train accuracy: 0.9667, loss: 0.024\n",
      "epoch (49): Train accuracy: 0.9667, loss: 0.023\n",
      "epoch (50): Train accuracy: 0.9750, loss: 0.022\n"
     ]
    }
   ],
   "source": [
    "#Define the training function\n",
    "def train(epoch, model, train_dataloader, optimizer, lossfunction):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_total, train_correct = 0.0, 0.0 \n",
    "    \n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Get the predicted output\n",
    "        predictions = model(X_batch)\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = lossfunction(predictions, y_batch)\n",
    "        \n",
    "        #Update the weights usning gradient descent with Adam optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Convert probabilities to multi-class predictions (reutrn the class with the maximal proability)\n",
    "        _, train_predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        #Calculate the training statistics\n",
    "        train_loss += loss.item()\n",
    "        train_total += y_batch.size(0)\n",
    "        train_correct += (train_predicted == y_batch).sum().item()\n",
    "\n",
    "    print(\"epoch (%d): Train accuracy: %.4f, loss: %.3f\" % (epoch, train_correct/train_total, train_loss/train_total))\n",
    "    \n",
    "    \n",
    "#Train the model\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train(epoch, model, train_dataloader, optimizer, lossfunction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41bad2c",
   "metadata": {},
   "source": [
    "## Test the model using test data (X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8fc9d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9667, macro f1_score: 0.9659\n"
     ]
    }
   ],
   "source": [
    "#Define the test function\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_correct, test_total = 0.0, 0.0\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            predictions = model(X_batch)\n",
    "            \n",
    "            #Convert probabilities to multi-class predictions (reutrn the class with the maximal proability)\n",
    "            _, test_predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "            test_total += y_batch.size(0)\n",
    "            test_correct += (test_predicted == y_batch).sum().item()\n",
    "            \n",
    "            y_pred += test_predicted.tolist()\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    print('Test accuracy: %.4f, macro f1_score: %.4f' % (test_correct / test_total, f1))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "#Test the model\n",
    "y_pred = test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d361d",
   "metadata": {},
   "source": [
    "## Output the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37c3ac28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "\n",
      "[[10  0  0]\n",
      " [ 0  8  1]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print('Confusion Matrix\\n')\n",
    "print(confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b09728",
   "metadata": {},
   "source": [
    "## Calculate accuracy and F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "456a8a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "Macro F1-score: 0.97\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(acc))\n",
    "print('Macro F1-score: {:.2f}'.format(f1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
