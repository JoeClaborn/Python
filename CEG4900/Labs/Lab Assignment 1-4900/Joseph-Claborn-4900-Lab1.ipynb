{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3e7773d",
   "metadata": {},
   "source": [
    "### CEG 4900 Trustworthy Machine Learning - Lab Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057fb92a",
   "metadata": {},
   "source": [
    "# <center>Adversarial Attacks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0a0d2",
   "metadata": {},
   "source": [
    "### 1. Overview\n",
    "The learning objective of this lab assignment is for students to understand adversarial attacks and defenses, including how to train a simple multi-class classification model (softmax regression) and a convolutional neural network for image classification, and how to perform adversarial attacks gainst these models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633487e0",
   "metadata": {},
   "source": [
    "#### Lecture notes. \n",
    "Detailed coverage of these topics can be found in the following:\n",
    "<li>Machine Learning Basics</li>\n",
    "<li>Evaluation Metrics for Classification</li>\n",
    "<li>Simple Feature-Space Adversarial Attack</li>\n",
    "<li>Gradient-based Adversarial Attack</li>\n",
    "\n",
    "#### Code demonstrations.\n",
    "<li>Code-Simple Feature-Space Adversarial Attack.ipynb</li>\n",
    "<li>Code-Gradient-based Adversarial Attack (FGSM).ipynb</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d253216",
   "metadata": {},
   "source": [
    "### 2. Submission\n",
    "You need to submit a detailed lab report with code, running results, and answers to the questions. If you submit <font color='red'>a jupyter notebook (“Firstname-Lastname-4900-Lab1.ipynb”)</font>, please fill in this file directly and place the code, running results, and answers in order for each question. If you submit <font color='red'>a PDF report (“Firstname-Lastname-4900-Lab1.pdf”) with code file (“Firstname-Lastname-4900-Lab1.py”)</font>, please include the screenshots (code and running results) with answers for each question in the report.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7802ac85",
   "metadata": {},
   "source": [
    "### 3. Questions (50 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799c0370",
   "metadata": {},
   "source": [
    "#### Preparations: import the required libraries and define functions\n",
    "\n",
    "Please run the following cell to import all the required libraries and define some necessary functions before complete the coding questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a857a726",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Put all the libraries here\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "#Put all the libraries here\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset, Subset\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Define the training function\n",
    "def train(epoch, model, train_dataloader, optimizer, lossfunction):\n",
    "    model.train()\n",
    "    \n",
    "    train_loss = 0.0\n",
    "    train_total, train_correct = 0.0, 0.0 \n",
    "    \n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #Get the predicted output\n",
    "        predictions = model(X_batch)\n",
    "\n",
    "        #Calculate the loss\n",
    "        loss = lossfunction(predictions, y_batch)\n",
    "        \n",
    "        #Update the weights usning gradient descent with Adam optimizer\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #Convert probabilities to multi-class predictions (reutrn the class with the maximal proability)\n",
    "        _, train_predicted = torch.max(predictions.data, 1)\n",
    "        \n",
    "        #Calculate the training statistics\n",
    "        train_loss += loss.item()\n",
    "        train_total += y_batch.size(0)\n",
    "        train_correct += (train_predicted == y_batch).sum().item()\n",
    "\n",
    "    print(\"epoch (%d): Train accuracy: %.4f, loss: %.3f\" % (epoch, train_correct/train_total, train_loss/train_total))\n",
    "\n",
    "#Define the test function for test_dataloader\n",
    "def test(model, test_dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    test_correct, test_total = 0.0, 0.0\n",
    "    y_test, y_pred = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            predictions = model(X_batch)\n",
    "            \n",
    "            _, test_predicted = torch.max(predictions.data, 1)\n",
    "            test_total += y_batch.size(0)\n",
    "            test_correct += (test_predicted == y_batch).sum().item()\n",
    "            \n",
    "            y_test += y_batch.tolist()\n",
    "            y_pred += test_predicted.tolist()\n",
    "\n",
    "    print('Test accuracy: %.4f' % (test_correct / test_total))\n",
    "    \n",
    "    return y_test, y_pred\n",
    "\n",
    "#Define the function that returns a predicted label for single input sample\n",
    "def predict_label(model, single_input):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        prediction = model(single_input)\n",
    "        _, predicted_label = torch.max(prediction.data, 1)\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "#Define the function that returns predicted probabilities for single input sample\n",
    "def predict_probabilities(model, single_input):\n",
    "    model.eval()  \n",
    "    with torch.no_grad():\n",
    "        prediction = model(single_input)\n",
    "        predicted_probabilities = torch.softmax(prediction, dim=1).squeeze(0)\n",
    "    \n",
    "    return predicted_probabilities\n",
    "\n",
    "#Define the function that returns model weight vector that is used to predict the target_label\n",
    "def weight_vector(model, target_label):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        weights = list(model.parameters())[0]\n",
    "    \n",
    "    return weights[target_label]\n",
    "\n",
    "#Define the function that plots the given images\n",
    "def plot_digits(instances, labels, images_per_row=5):\n",
    "    for i in range(len(instances)):\n",
    "        idx = i // images_per_row\n",
    "        idy = i % images_per_row \n",
    "        ax[idx, idy].imshow(instances[i].squeeze(), cmap=\"gray\")\n",
    "        ax[idx, idy].set_title(class_names[labels[i]])\n",
    "        ax[idx, idy].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b48b09",
   "metadata": {},
   "source": [
    "## <font color='blue'>Simple Feature-space Adversarial Attack</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4353ca6",
   "metadata": {},
   "source": [
    "#### Load and preprocess the `Wine Recognition` data\n",
    "\n",
    "In Question 1, Question 2, Question 3, and Question 4, you will be using the `Wine Recognition Dataset` to train a simple multi-class classification (softmax regression) model to predict the `class` of a given wine (`0: class_0, 1: class_1, 2: class_2`), and perform a feature-space adversarial attack against this trained classification model. First, please run the following cell to load the dataset and convert the data to PyTorch tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98706103",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_wine' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Load wine recognition dataset\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m wine \u001b[38;5;241m=\u001b[39m \u001b[43mload_wine\u001b[49m()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Assign features and labels to X and y\u001b[39;00m\n\u001b[0;32m      5\u001b[0m X, y \u001b[38;5;241m=\u001b[39m wine\u001b[38;5;241m.\u001b[39mdata, wine\u001b[38;5;241m.\u001b[39mtarget\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_wine' is not defined"
     ]
    }
   ],
   "source": [
    "#Load wine recognition dataset\n",
    "wine = load_wine()\n",
    "\n",
    "#Assign features and labels to X and y\n",
    "X, y = wine.data, wine.target\n",
    "#Suppress scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "#Class names\n",
    "print(\"Class names: \", wine.target_names)\n",
    "#Feature names\n",
    "print(\"Feature names: \", wine.feature_names)\n",
    "#Feature number\n",
    "print(\"Number of Features: \", X.shape[1])\n",
    "\n",
    "#Split the data into two sets: 75% for training and 25% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create a TensorDataset for training and testing, respectively\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Create DataLoaders: here, we use mini-batch gradient descent, so need to specify the batch size\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c28237ee",
   "metadata": {},
   "source": [
    "#### Question 1 (7 points):  \n",
    "**First, set up the hyperparameters, and then define a `MultiClassification` to construct a single-layer multi-class classification model (softmax regression). Note: the number of features is 13 and the number of classes is 3** \n",
    "\n",
    "**After that, implement function `answer_one( )` to instantiate a model from the defined `MultiClassification`, call the pre-defined function `train(epoch, model, train_dataloader, optimizer, lossfunction)` to train this model, and call the pre-defined function `test(model, test_dataloader)` to evaluate the trained model. Also, use the returned `y_test` and `y_pred` to calculate micro F1 score and macro F1 score.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2312b55",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01moptim\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "#Define a class MultiClassification to construct a single-layer multi-class classification model\n",
    "class MultiClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiClassification, self).__init__()\n",
    "        #Code here: define a fully-connected layer\n",
    "        #The input is the number of features and the output is the number of classes\n",
    "        #Set bias as False\n",
    "        self.fc = nn.Linear(in_features=13, out_features=3, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #Code here: set up the forward calculation\n",
    "        y = torch.softmax(self.fc(x), dim=1)\n",
    "        \n",
    "        return y\n",
    "\n",
    "#Set up the hyperparameters    \n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Code here: based on your computing resources, assign epochs as a number in the range of [30, 50]\n",
    "epochs = 40                      \n",
    "learning_rate = 0.01                 \n",
    "weight_decay = 5e-4                 \n",
    "lossfunction = nn.CrossEntropyLoss()\n",
    "\n",
    "def answer_one():\n",
    "    #Code here: instantiate a model from the defined MultiClassification  \n",
    "    model = MultiClassification()\n",
    "    \n",
    "    #Code here: specify the Adam optimizer used for mini-batch gradient descent for model training\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "    \n",
    "    #Train the model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        #Code here: call train() function for model training: you need to pass the corresponding parameters to this function\n",
    "        train(epoch, model, train_dataloader, optimizer, lossfunction)\n",
    "    \n",
    "    #Test the model: \n",
    "    #Code here: call test() function to evaluate the trained model: you need to pass the corresponding parameters to this function\n",
    "    y_test, y_pred = test(model, test_dataloader)\n",
    "    \n",
    "    #Code here: use y_test and y_pred to calculate the macro F1 and micro F1 using sklearn function\n",
    "    macrof1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "    microf1 = f1_score(y_test, y_pred, average = 'micro')\n",
    "    \n",
    "    return model, macrof1, microf1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "model, macrof1, microf1 = answer_one()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750a8ae",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 1 (double click here to answer the questions in this cell):</font>  \n",
    "The number of epochs you used for softmax regression training is: ( 40 ) <br>\n",
    "The test accuracy is: ( ) <br>\n",
    "The test macro f1 score is: ( ) <br>\n",
    "The test micro f1 score is: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9290d7",
   "metadata": {},
   "source": [
    "#### Randomly select an test input from test_dataset to perturb and select a target label to attack\n",
    "\n",
    "Please run the following cell to select a random test input from test_dataset and a target label, which will be used for the following questions to perform simple feature-space adversarial attack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "745c3f80",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Set the random seed\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#Number of test samples\u001b[39;00m\n\u001b[0;32m      5\u001b[0m number_of_samples \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_dataset)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "#Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Number of test samples\n",
    "number_of_samples = len(test_dataset)\n",
    "#Get a random index from [0, number_of_samples)\n",
    "index = np.random.randint(number_of_samples)\n",
    "\n",
    "#Select the test input to perturb\n",
    "test_input = test_dataset[index][0]\n",
    "test_input_label = test_dataset[index][1]\n",
    "\n",
    "#Here, we perform targeted adversarial attack: change the original_label to the target_label\n",
    "original_label = test_input_label.item() #class_1\n",
    "target_label = 2 #class_2\n",
    "\n",
    "print(\"The index of the test input: \", index)\n",
    "print(\"Test input feature vector: \", test_input)\n",
    "print(\"Test input original label: \", original_label, wine.target_names[original_label])\n",
    "print(\"Target label: \", target_label, wine.target_names[target_label])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59824e93",
   "metadata": {},
   "source": [
    "#### Question 2 (7 points): \n",
    "\n",
    "**Implement the function `answer_two(k)` to search for a good instance to guide the simple feature-space adversarial attack, where you need to assign the value of `k` first to specify the number of top target samples close to decision boundary you would like to collect for good instance searching.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0602d7aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 46\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m good_instance\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m#Run your function in the cell to return the results\u001b[39;00m\n\u001b[1;32m---> 46\u001b[0m good_instance \u001b[38;5;241m=\u001b[39m \u001b[43manswer_two\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36manswer_two\u001b[1;34m(k)\u001b[0m\n\u001b[0;32m      6\u001b[0m target_samples \u001b[38;5;241m=\u001b[39m [] \u001b[38;5;66;03m#Test samples that are predicted as the target label\u001b[39;00m\n\u001b[0;32m      7\u001b[0m target_probs \u001b[38;5;241m=\u001b[39m []   \u001b[38;5;66;03m#The prediction probabilities for each test sample\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sample, true_label \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtest_dataset\u001b[49m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#Code here: using predict_label() to predict label for each sample (note: please use sample.unsqueeze(0) to ensure batch dimensition)\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m predict_label(sample\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#Code here: using predict_probabilities() to predict probabilities for each sample (note: please use sample.unsqueeze(0) to ensure batch dimensition)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "#Code here: assign k as any integer in the range of [5,10]\n",
    "k = 7\n",
    "\n",
    "def answer_two(k):\n",
    "    #Obtain all the test samples with the target label\n",
    "    target_samples = [] #Test samples that are predicted as the target label\n",
    "    target_probs = []   #The prediction probabilities for each test sample\n",
    "    \n",
    "    for sample, true_label in test_dataset:\n",
    "        #Code here: using predict_label() to predict label for each sample (note: please use sample.unsqueeze(0) to ensure batch dimensition)\n",
    "        predicted_label = predict_label(sample.unsqueeze(0))\n",
    "        #Code here: using predict_probabilities() to predict probabilities for each sample (note: please use sample.unsqueeze(0) to ensure batch dimensition)\n",
    "        predicted_proabilities = predict_probabilities(sample.unsqueeze(0))\n",
    "\n",
    "        #Code here: append sample amd its proabilities to target_samples and target_probs if the predicted_label is target_label\n",
    "        if predicted_label == target_label:\n",
    "            target_samples.append(sample)\n",
    "            target_probs.append(predicted_proabilities)\n",
    "\n",
    "    target_samples = torch.stack(target_samples)\n",
    "    target_probs = torch.stack(target_probs)\n",
    "    \n",
    "    #Code here: rank target samples by highest probability for the original label\n",
    "    closest_to_boundary_indices = torch.argsort(torch.max(target_probs, dim=1).values)\n",
    "    \n",
    "    #Code here: find the indices of top k target samples that are closest to decision boundary\n",
    "    top_k_boundary_indices = closest_to_boundary_indices[:k]\n",
    "    \n",
    "    #Code here: calculate manhattan distance (L1 distance) between test_input and target_samples\n",
    "    distances = torch.sum(torch.abs(target_samples - test_input), dim=1)\n",
    "    \n",
    "    #Code here: find the indices of target samples that have shortest distance to the test_input \n",
    "    nearest_neighbors_indices = torch.argsort(distances)\n",
    "    \n",
    "    #The good instance is initialized as the nearest neighbor\n",
    "    good_instance = target_samples[nearest_neighbors_indices[0]]\n",
    "\n",
    "    #Code here: find a good instance: one of the test_input's nearest neighbors that is among top k target samples close to decision boundary\n",
    "    for i in nearest_neighbors_indices:\n",
    "        if i in top_k_boundary_indices:\n",
    "            good_instance = target_samples[i]\n",
    "            break\n",
    "        \n",
    "    return good_instance\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "good_instance = answer_two(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0201f014",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 2 (double click here to answer the questions in this cell):</font>  \n",
    "The k you used to search for top target samples close to decision boundary is: ( 7 ) <br>\n",
    "The good instance you found for guidance is: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaa2cc8",
   "metadata": {},
   "source": [
    "#### Question 3 (5 points): \n",
    "\n",
    "**Implement the function `answer_three( )` to find feature indices in descending order of feature importance, such that we can use greedy search method to perturb these features from the most important one to the least important one. When you have a feature index, you can get its feature name using `wine.feature_names[feature_index]`. For example, if the feature index is 5, then its feature name is `wine.feature_names[5]`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c6a9ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weight_vector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 17\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m featue_importances_indices, most_important, least_important\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Run your function in the cell to return the results\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m featue_importances_indices, most_important, least_important \u001b[38;5;241m=\u001b[39m \u001b[43manswer_three\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 3\u001b[0m, in \u001b[0;36manswer_three\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manswer_three\u001b[39m():\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#Code here: use weight_vector() to extract feature importances for the target label which can be quantified by the weight vector to predict the target label\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     featue_importances \u001b[38;5;241m=\u001b[39m \u001b[43mweight_vector\u001b[49m(target_label)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#Code here: find the indices of features from the most important to the least important \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     featue_importances_indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margsort(featue_importances, descending\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weight_vector' is not defined"
     ]
    }
   ],
   "source": [
    "def answer_three():\n",
    "    #Code here: use weight_vector() to extract feature importances for the target label which can be quantified by the weight vector to predict the target label\n",
    "    featue_importances = weight_vector(target_label)\n",
    "\n",
    "    #Code here: find the indices of features from the most important to the least important \n",
    "    featue_importances_indices = torch.argsort(featue_importances, descending = True).tolist()\n",
    "    \n",
    "    #Code here: extract the most important feature (name)\n",
    "    most_important = wine.feature_names[featue_importances_indices[0]]\n",
    "    \n",
    "    #Code here: extract the least important feature (name)\n",
    "    least_important = wine.feature_names[featue_importances_indices[-1]]\n",
    "    \n",
    "    return featue_importances_indices, most_important, least_important\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "featue_importances_indices, most_important, least_important = answer_three()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b871884e",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 3 (double click here to answer the questions in this cell):</font>  \n",
    "The feature indices in descending order of feature importance are: ( ) <br>\n",
    "The most important feature is (fill in its feature name): ( ) <br>\n",
    "The least important feature is (fill in its feature name): ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a746ea0",
   "metadata": {},
   "source": [
    "#### Question 4 (8 points): \n",
    "\n",
    "**Implement the function `answer_four( )` to perturb the `test_input` by directly updating the value of a specific feature in the original test input to the value of that in the good instance.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728947ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "adversarial_example = test_input.clone()\n",
    "\n",
    "def answer_four():\n",
    "    #Code here: perturb the features from the most important one to the least important one\n",
    "    for feature in featue_importances_indices:\n",
    "        adversarial_example[feature] = good_instance[feature]\n",
    "\n",
    "    #Code here: calculate the size of perturbation\n",
    "    perturbation_size = torch.sum(torch.abs(adversarial_example - test_input)).item()\n",
    "    \n",
    "    return adversarial_example, perturbation_size\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "adversarial_example, perturbation_size = answer_four()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226d004b",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 4 (double click here to answer the questions in this cell):</font>  \n",
    "The adversarial example is: ( ) <br>\n",
    "The size of perturbation is: ( ) <br>\n",
    "Based on the previous steps, please summarize why we need to find a good instance and use feature importances to facilitate adversarial attack: ( ), and the advantage and disadvantage are: ( )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6853a460",
   "metadata": {},
   "source": [
    "## <font color='blue'>Gradient-based Adversarial Attack</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a769f5",
   "metadata": {},
   "source": [
    "#### Load and preprocess the `Fashion-MNIST` data\n",
    "\n",
    "In Question 5 and Question 6, you will be using the `Fashion-MNIST` to train a convolutional neural network model to predict the fashion product name of a given image, and perform a gradient-based adversarial attack against this trained fashion product image classification model. First, download the `Fashion-MNIST` data directly from PyTorch and convert the dataset into Tensor used by PyTorch. \n",
    "\n",
    "Loading `Fashion-MNIST` data of 70,000 images may take some time. The downloaded `Fashion-MNIST` data file will be stored in  `data` folder under the same directory with your notebook/python file.\n",
    "\n",
    "The size of each image in `Fashion-MNIST` data is 28x28. Each image is fed as 28x28 matrix to convolutional neural network directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19561043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the dataset into Tensor used by PyTorch\n",
    "transform=transforms.Compose([\n",
    "         transforms.ToTensor(),\n",
    "        ])\n",
    "\n",
    "#Download the Fashion-MNIST data directly from PyTorch\n",
    "#The downloaded datasets are stored in data folder under the same folder with this jupyter notebook file\n",
    "train_dataset = datasets.FashionMNIST('./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "#Load the datasets into DataLoader\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=0)\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "#Plot some Fashion-MNIST examples\n",
    "fig, ax = plt.subplots(2, 5, figsize=(8, 4))\n",
    "dataiter = iter(train_dataloader)\n",
    "samples = next(dataiter)\n",
    "example_images = samples[0][:10]\n",
    "example_labels = samples[1][:10]\n",
    "plot_digits(example_images, example_labels, images_per_row=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c978095",
   "metadata": {},
   "source": [
    "#### Question 5 (7 points):  \n",
    "**First, set up the epochs (all the other hyperparameters are defined in Question 1), and then define a class `CNN` to construct all the layers in the convolutional neural network.** \n",
    "\n",
    "**After that, implement function `answer_five( )` to instantiate a CNN model from the defined `CNN`, call the pre-defined function `train(epoch, model, train_dataloader, optimizer, lossfunction)` to train the CNN model, and call the pre-defined function `test(model, test_dataloader)` to evaluate the trained CNN model. Also, use the returned `y_test` and `y_pred` to calculate micro F1 score and macro F1 score.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bf240",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Set the random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#Code here: based on your computing resources, assign epochs as a number in the range of [5, 10]  \n",
    "epochs = 7                \n",
    "\n",
    "#Code here: define a class CNN to construct all the layers in the convolutional neural network\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=10, kernal_size=1)                                   #Convolution: 1 input channel to 10 channels with kernel_size 5\n",
    "        self.conv2 = nn.Conv2d(in_channels=10, out_channels=20, kernal_size=5)                                   #Convolution: 10 channels to 20 channels with kernel_size 5\n",
    "        self.fc1=nn.Linear(in_features=320, out_features=50)                                   #Fully-connected layer: 320 neurons to 50 neurons\n",
    "        self.fc2=nn.Linear(in_features=50, out_features=10)                                   #Fully-connected layer: 50 neurons to 10 neurons\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))                                   #Use ReLU as activation function for the convolution layer \n",
    "        x = F.max_pool2d(x, kernal_size=2)                                   #Apply max_pooling on the output of the convolution layer with size 2\n",
    "        x = F.relu(self.conv2(x))                                   #Use ReLU as activation function for the convolution layer\n",
    "        x = F.max_pool2d(x, kernal_size=2)                                   #Apply max_pooling on the output of the convolution layer with size 2\n",
    "        x = x.view(x.size(0), -1)                                   #Flatten all channels to a single vector\n",
    "        x = F.relu(self.fc1(x))                                   #Use ReLU as activation function for the fully-connected layer\n",
    "        x = self.fc2(x)                                   #Obtain the final output with 10 neurons for 10 classes\n",
    "        return x\n",
    "\n",
    "def answer_five():    \n",
    "    #Code here: instantiate a CNN model from the defined CNN class  \n",
    "    model = CNN()\n",
    "    \n",
    "    #Code here: specify the optimizer used for mini-batch gradient descent for model training\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "    \n",
    "    #Train the model\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        #Code here: call train() function for model training: you need to pass the corresponding parameters to this function\n",
    "        train(epoch, model, train_dataloader, optimizer, lossfunction)\n",
    "    \n",
    "    #Test the model: \n",
    "    #Code here: call test() function to evaluate the trained model: you need to pass the corresponding parameters to this function\n",
    "    y_test, y_pred = test(model, test_dataloader)\n",
    "    \n",
    "    #Code here: use y_test and y_pred to calculate the macro F1 and micro F1 using sklearn function\n",
    "    macrof1 = f1_score(y_test, y_pred, average = 'macro')\n",
    "    microf1 = f1_score(y_test, y_pred, average = 'micro')\n",
    "    \n",
    "    return model, macrof1, microf1\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "model, macrof1, microf1 = answer_five()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b4d7ca",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 5 (double click here to answer the questions in this cell):</font>  \n",
    "The number of epochs you used for CNN training is: ( 7 ) <br>\n",
    "The test accuracy is: ( ) <br>\n",
    "The test macro f1 score is: ( ) <br>\n",
    "The test micro f1 score is: ( )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74087a8",
   "metadata": {},
   "source": [
    "#### Question 6 (8 points):\n",
    "**Based on the convolutional neural network `model` trained in Question 5, please implement a fast gradient sign method attack in function `answer_six(epsilon, image_input, true_label)`, and then based on your implementation, answer the corresponding question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38e6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_six(epsilon, image_input, true_label):\n",
    "    #Set requires_grad attribute of image_input tensor as true, which will be used to get the gradient\n",
    "    image_input.requires_grad = True\n",
    "    \n",
    "    #Code here: pass the input image through the trained model to get the output\n",
    "    prediction = model(image_input)\n",
    "\n",
    "    #Code here: calculate the loss\n",
    "    loss = lossfunction(prediction, torch.tensor([true_label]))\n",
    "\n",
    "    #Code here: zero all existing gradients\n",
    "    model.zero_grad()\n",
    "\n",
    "    #Code here: calculate gradients of loss in backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    #Code here: obtain the gradient regarding input image\n",
    "    image_input_grad = image_input.grad.data\n",
    "\n",
    "    #Perform FGSM attack\n",
    "    #Code here: obtain the sign of the gradient\n",
    "    sign_grad = image_input_grad.sign()\n",
    "\n",
    "    #Code here: generate the perturbed image by adding the perturbation with epsilon and sign of gradient to the input image\n",
    "    perturbed_image = image_input + epsilon * sign_grad\n",
    "\n",
    "    #Code here: add clipping to maintain [0,1] range\n",
    "    perturbed_image = torch.clamp(perturbed_image, 0, 1)\n",
    "\n",
    "    return perturbed_image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b673a0",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 6 (double click here to answer the questions in this cell):</font>  \n",
    "Based on the previous implementation, please summarize the steps of adversarial attack using fast gradient sign method: ( ), and explain why FGSM uses the sign of the gradient instead of the raw gradient: ( )."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33203f79",
   "metadata": {},
   "source": [
    "#### Question 7 (8 points):\n",
    "**Implement function `answer_seven( )` to call the FGSM function implemented in `answer_six(epsilon, image_input, true_label)` to generate adversarial examples, and also evaluate how varying `epsilon` on the attack performance and the input images.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d737bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilons for the size of perturbation\n",
    "epsilons = [0, .05, .1, .15, .2, .25]\n",
    "\n",
    "#Choose a random test image as input\n",
    "#Set the random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Number of test samples\n",
    "number_of_images = len(test_dataset)\n",
    "#Get a random index from [0, number_of_samples)\n",
    "image_index = np.random.randint(number_of_samples, size=1)\n",
    "\n",
    "#Select the test input to perturb\n",
    "test_images = torch.stack([test_dataset[i][0] for i in image_index])\n",
    "test_imagelabels = torch.tensor([test_dataset[i][1] for i in image_index])\n",
    "\n",
    "def answer_seven():\n",
    "    adversarial_examples = []\n",
    "    true_labels = []\n",
    "    adv_labels = []\n",
    "\n",
    "    for epsilon in epsilons:\n",
    "        #Code here: call answer_six() to generate the perturbed image: you need to pass the corresponding parameters to this function\n",
    "        perturbed_image = answer_six(epsilon, test_images[0].unsqueeze(0), test_imagelabels[0].item())\n",
    "        #Code here:: use predict_label() to classify the perturbed image\n",
    "        adv_label = predict_label(perturbed_image)\n",
    "    \n",
    "        adversarial_examples.append(perturbed_image.detach().numpy())\n",
    "        true_labels.append(test_imagelabels)\n",
    "        adv_labels.append(adv_label)\n",
    "    \n",
    "    return adversarial_examples, true_labels, adv_labels\n",
    "\n",
    "#Run your function in the cell to return the results\n",
    "adversarial_examples, true_labels, adv_labels = answer_seven()\n",
    "\n",
    "#Plot adversarial example at each epsilon\n",
    "plt.figure(figsize=(12,20))\n",
    "for i in range(len(epsilons)):\n",
    "    plt.subplot(1, len(epsilons), i + 1)\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.ylabel(\"Eps: {}\".format(epsilons[i]), fontsize=14)\n",
    "    orig, adv, ex = true_labels[i], adv_labels[i], adversarial_examples[i][0].squeeze(0) \n",
    "    plt.title(\"Ori:{} -> \\nAdv: {}\".format(class_names[orig], class_names[adv]))\n",
    "    plt.imshow(ex, cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a0abc",
   "metadata": {},
   "source": [
    "#### <font color='red'>Answer 7 (double click here to answer the questions in this cell):</font>  \n",
    "The original label name is: ( ) <br>\n",
    "After performing adversarial attack using fast gradient sign method, you get a successful adversarial example when the epsilon is: ( ) <br>\n",
    "The adversarial label name is: ( ) <br>\n",
    "Please summarize the impact of perturbations with different epsilons on the attack performance and the visual quality of the input image: ( )."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
